# IV Ingestion API

A comprehensive Node.js/Express API for home inspection data processing with PostgreSQL database, JWT authentication, comprehensive testing framework, and complete SDK ecosystem.

## üöÄ Features

### Core Infrastructure
- **Complete API Infrastructure**: Express.js server with production middleware
- **Database Schema**: PostgreSQL with comprehensive relational schema for home inspections
- **Authentication**: JWT with access/refresh tokens and role-based access control
- **Validation**: Comprehensive request validation using Joi schemas
- **Error Handling**: Structured error responses with detailed logging
- **API Documentation**: OpenAPI 3.0 with Swagger UI
- **Testing**: Jest framework with unit and integration tests
- **Security**: Rate limiting, CORS, helmet, and input sanitization
- **Logging**: Winston with JSON format and log rotation
- **Docker Support**: Complete containerization with Docker Compose

### File Processing & Queue System (Increment 2)
- **Redis & Bull Queue System**: Scalable async processing with clustering support
- **Multi-Format Parser Engine**: 
  - PDF Parser: Text extraction, table detection, metadata extraction
  - Word Parser: Document parsing with formatting preservation
  - Excel Parser: Multi-sheet data extraction with formula support
  - OCR Parser: Image processing with Tesseract.js
- **File Upload Handling**: Multer-based uploads with virus scanning and deduplication
- **Data Extraction**: Intelligent inspection data extraction with ML-ready architecture
- **Queue Management**: Background job processing with configurable workers
- **Processing Status Tracking**: Real-time status updates with progress monitoring
- **Error Handling & Recovery**: Graceful handling with retry mechanisms and dead letter queues
- **Performance Optimization**: Stream processing, parallel processing, and resource monitoring

### Admin Dashboard & Monitoring (Increment 3)
- **React 18 Admin Dashboard**: TypeScript-based admin interface with Material-UI
- **Real-time Monitoring**: Live queue status, system metrics, and user activity
- **File Testing Interface**: Upload and test file processing with real-time feedback
- **API Testing Playground**: Interactive API testing with request/response logging
- **User Management**: Admin user management with role-based access
- **Debug Tools**: System diagnostics, log viewing, and performance monitoring
- **Notification System**: Real-time notifications for system events and alerts

### User Frontend Interface (Increment 4)
- **Modern React 18 Interface**: TypeScript-based user interface with Material-UI
- **Authentication System**: JWT-based login/registration with password reset
- **File Upload Interface**: Drag-and-drop file upload with progress tracking
- **Inspection Dashboard**: View and manage inspection reports and findings
- **Data Visualization**: Charts and graphs for inspection data analysis
- **Mobile-First Design**: Responsive design optimized for all devices
- **Dark/Light Theme**: Theme switching with system preference detection

### API Integration & Documentation (Increment 5)
- **Comprehensive API Documentation**: OpenAPI 3.0 specification with interactive Swagger UI
- **JavaScript/TypeScript SDK**: Complete client library with TypeScript definitions
- **Python SDK**: Object-oriented Python client with async support
- **Webhook System**: Real-time event notifications with signature verification
- **Rate Limiting**: Tiered rate limiting with sliding windows and Redis integration
- **Real-time Features**: WebSocket integration and Server-Sent Events
- **Integration Capabilities**: Third-party integrations and batch operations
- **Developer Experience**: Interactive examples, tutorials, and testing tools

## üìã Prerequisites

- Node.js 18+ 
- PostgreSQL 15+
- Redis 7+ (required for queue system)
- Docker & Docker Compose (for containerized setup)

## üõ†Ô∏è Installation

### Quick Start (Recommended)

1. **Clone and setup**
   ```bash
   git clone <repository-url>
   cd iv-ingestion
   npm install
   ```

2. **Run development setup**
   ```bash
   npm run setup:dev
   ```

3. **Start the server**
   ```bash
   npm run dev
   ```

4. **Start the worker (in a separate terminal)**
   ```bash
   npm run worker
   ```

### Manual Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd iv-ingestion
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   cp env.example .env
   # Edit .env with your configuration
   ```

4. **Set up PostgreSQL and Redis**
   
   **Option A: Docker (Recommended)**
   ```bash
   docker-compose up -d
   npm run migrate
   npm run seed
   ```
   
   **Option B: Local Installation**
   ```bash
   # Install PostgreSQL
   brew install postgresql
   brew services start postgresql
   
   # Install Redis
   brew install redis
   brew services start redis
   
   # Create databases
   createdb iv_ingestion
   createdb iv_ingestion_test
   
   # Run migrations
   npm run migrate
   npm run seed
   ```

5. **Start the development server**
   ```bash
   npm run dev
   ```

6. **Start the worker process**
   ```bash
   npm run worker
   ```

### Option 2: Docker Setup

1. **Clone and navigate to project**
   ```bash
   git clone <repository-url>
   cd iv-ingestion
   ```

2. **Start services with Docker Compose**
   ```bash
   docker-compose up -d
   ```

3. **Run migrations and seeds**
   ```bash
   docker-compose exec api npm run db:setup
   ```

The API will be available at `http://localhost:3000`

## üìö API Documentation

Once the server is running, you can access:

- **Swagger UI**: `http://localhost:3000/api-docs`
- **Health Check**: `http://localhost:3000/health`
- **Queue Statistics**: `http://localhost:3000/api/v1/files/queue/stats`
- **Supported File Types**: `http://localhost:3000/api/v1/files/supported-types`

## üîÑ File Processing System

### Supported File Types
- **PDF**: `.pdf` - Text extraction, table detection, metadata
- **Word Documents**: `.doc`, `.docx` - Text and formatting extraction
- **Excel Files**: `.xls`, `.xlsx`, `.csv` - Multi-sheet data extraction
- **Images**: `.jpg`, `.jpeg`, `.png`, `.tiff`, `.tif`, `.bmp` - OCR processing

### Processing Pipeline
1. **File Upload**: Multer-based upload with validation and virus scanning
2. **Queue Processing**: Jobs added to Redis-based Bull queue
3. **Parsing**: Multi-format parser engine extracts text and structure
4. **Data Extraction**: Intelligent extraction of property info, inspector details, and findings
5. **Status Tracking**: Real-time progress updates and completion notifications

### Queue Management
- **File Processing Queue**: Handles document parsing and data extraction
- **OCR Processing Queue**: Specialized queue for image processing
- **Data Extraction Queue**: Advanced data extraction and categorization
- **Notifications Queue**: Status updates and completion notifications
- **Dead Letter Queue**: Failed jobs for manual review

### Worker Processes
```bash
# Start file processing worker
npm run worker

# Monitor queue statistics
curl http://localhost:3000/api/v1/files/queue/stats
```

## üóÑÔ∏è Database Schema

The application includes a comprehensive PostgreSQL schema with the following tables:

- **users**: User authentication and roles
- **properties**: Property information and metadata
- **files**: File upload tracking and processing status
- **processing_jobs**: Job queue for file processing
- **inspections**: Inspection reports linking properties and files
- **findings**: Detailed findings from inspections
- **audit_logs**: System audit trail

## üîê Authentication

The API uses JWT authentication with the following features:

- **Access Tokens**: 15-minute expiration
- **Refresh Tokens**: 7-day expiration
- **Role-based Access**: User, Admin, and Inspector roles
- **API Keys**: Alternative authentication for server-to-server communication

## üö¶ Rate Limiting

The API implements tiered rate limiting:

| Tier | API Requests | File Uploads | Window |
|------|-------------|--------------|---------|
| Free | 100 | 10 | 15 min / 24 hours |
| Pro | 1,000 | 100 | 15 min / 24 hours |
| Enterprise | 10,000 | 1,000 | 15 min / 24 hours |

Rate limit headers are included in all responses:
```
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 999
X-RateLimit-Reset: 1640995200000
```

## üîó Webhooks

The API supports real-time webhook notifications for:

- **processing.started**: File processing initiated
- **processing.progress**: Processing progress updates
- **processing.completed**: File successfully processed
- **processing.failed**: Processing encountered error
- **inspection.created**: New inspection record created
- **inspection.updated**: Inspection data modified
- **finding.added**: New finding discovered
- **user.registered**: New user account created

### Webhook Security
Each webhook delivery includes an HMAC-SHA256 signature for verification.

## üì¶ SDKs

### JavaScript/TypeScript SDK

```bash
npm install @iv-ingestion/sdk
```

```typescript
import { IVIngestionClient } from '@iv-ingestion/sdk';

const client = new IVIngestionClient({
  baseURL: 'https://api.iv-ingestion.com/v1',
  apiKey: 'your-api-key'
});

// Upload a file
const result = await client.uploadFile({
  file: fileBuffer,
  metadata: { propertyId: '123' }
});

// Monitor processing
client.on('processing:progress', (progress) => {
  console.log(`Processing: ${progress.progress}%`);
});
```

### Python SDK

```bash
pip install iv-ingestion
```

```python
from iv_ingestion import IVIngestionClient

client = IVIngestionClient(
    base_url="https://api.iv-ingestion.com/v1",
    api_key="your-api-key"
)

# Upload a file
with open("inspection.pdf", "rb") as f:
    result = await client.upload_file(
        file=f,
        metadata={"property_id": "123"}
    )

# Monitor processing
async for progress in client.monitor_processing(result.file_id):
    print(f"Processing: {progress.progress}%")
```

## üñ•Ô∏è Admin Dashboard

Access the admin dashboard at `http://localhost:3001`:

- **System Overview**: Real-time metrics and system health
- **Queue Monitoring**: Live queue status and worker information
- **File Testing**: Upload and test file processing
- **API Testing**: Interactive API testing playground
- **User Management**: Admin user management interface
- **Debug Tools**: System diagnostics and log viewing

**Admin Login**: `admin@example.com` / `admin123`

## üë§ User Frontend

Access the user frontend at `http://localhost:3002`:

- **Dashboard**: Overview of inspections and findings
- **File Upload**: Drag-and-drop file upload interface
- **Inspections**: View and manage inspection reports
- **Profile**: User profile and settings management
- **Data Visualization**: Charts and graphs for analysis

## üß™ Testing

### Run Tests
```bash
# Unit tests
npm test

# Integration tests
npm run test:integration

# Test coverage
npm run test:coverage

# E2E tests
npm run test:e2e
```

### Test API Endpoints
```bash
# Test file upload
curl -X POST http://localhost:3000/api/v1/files/upload \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@test-file.pdf" \
  -F "metadata={\"propertyId\": \"123\"}"

# Test health check
curl http://localhost:3000/health

# Test queue status
curl http://localhost:3000/api/v1/files/queue/stats
```

## üìä Monitoring

### Health Checks
- **API Health**: `GET /health`
- **Database Health**: `GET /health/db`
- **Redis Health**: `GET /health/redis`
- **Queue Health**: `GET /health/queue`

### Metrics
- **System Metrics**: `GET /admin/metrics`
- **Queue Statistics**: `GET /admin/queues`
- **User Activity**: `GET /admin/users/activity`
- **Error Rates**: `GET /admin/errors`

## üîß Configuration

### Environment Variables
```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/iv_ingestion
DATABASE_TEST_URL=postgresql://user:pass@localhost:5432/iv_ingestion_test

# Redis
REDIS_URL=redis://localhost:6379

# JWT
JWT_SECRET=your-jwt-secret
JWT_REFRESH_SECRET=your-refresh-secret

# File Upload
MAX_FILE_SIZE=10485760
UPLOAD_PATH=./uploads

# Queue
QUEUE_CONCURRENCY=5
QUEUE_RETRY_ATTEMPTS=3

# API
API_PORT=3000
NODE_ENV=development
```

### Docker Configuration
```yaml
# docker-compose.yml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/iv_ingestion
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=iv_ingestion
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
```

## üöÄ Deployment

### Production Deployment
```bash
# Build production image
docker build -t iv-ingestion:latest .

# Run with production config
docker run -d \
  -p 3000:3000 \
  -e NODE_ENV=production \
  -e DATABASE_URL=your-production-db-url \
  -e REDIS_URL=your-production-redis-url \
  iv-ingestion:latest
```

### Environment-Specific Configs
- **Development**: `npm run dev`
- **Staging**: `npm run start:staging`
- **Production**: `npm run start:prod`

## üìà Performance

### Optimization Features
- **Stream Processing**: Memory-efficient file processing
- **Parallel Processing**: Multi-worker queue processing
- **Caching**: Redis-based caching for frequently accessed data
- **Connection Pooling**: Database connection optimization
- **Compression**: Gzip compression for API responses

### Benchmarks
- **File Upload**: < 2 seconds for 10MB files
- **Processing**: 30-60 seconds for typical inspection reports
- **API Response**: < 200ms for data queries
- **Concurrent Users**: 100+ simultaneous users supported

## üîí Security

### Security Features
- **JWT Authentication**: Secure token-based authentication
- **Rate Limiting**: Protection against abuse
- **Input Validation**: Comprehensive request validation
- **SQL Injection Protection**: Parameterized queries
- **XSS Protection**: Input sanitization and output encoding
- **CORS Configuration**: Cross-origin request protection
- **Helmet.js**: Security headers and middleware

### Best Practices
- Use HTTPS in production
- Rotate JWT secrets regularly
- Monitor rate limit violations
- Implement proper error handling
- Use environment variables for secrets
- Regular security audits

## ü§ù Contributing

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Guidelines
- Follow TypeScript best practices
- Write comprehensive tests
- Update documentation
- Follow the existing code style
- Add proper error handling

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

- **Documentation**: [docs.iv-ingestion.com](https://docs.iv-ingestion.com)
- **API Reference**: [api.iv-ingestion.com/docs](https://api.iv-ingestion.com/docs)
- **Issues**: [GitHub Issues](https://github.com/iv-ingestion/api/issues)
- **Email**: support@iv-ingestion.com

## üó∫Ô∏è Roadmap

### Upcoming Features
- **Machine Learning Integration**: AI-powered finding classification
- **Advanced Analytics**: Business intelligence dashboard
- **Mobile App**: React Native mobile application
- **API Versioning**: Backward-compatible API versions
- **Multi-tenancy**: Support for multiple organizations
- **Advanced Reporting**: Custom report generation
- **Integration Hub**: Third-party system integrations

### Version History
- **v1.0.0**: Initial release with core API functionality
- **v1.1.0**: File processing and queue system
- **v1.2.0**: Admin dashboard and monitoring
- **v1.3.0**: User frontend interface
- **v1.4.0**: SDKs and comprehensive documentation 